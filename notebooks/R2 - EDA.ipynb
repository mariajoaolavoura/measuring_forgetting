{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Goal*: find out if the dataset fits the data requirements\n",
    "\n",
    "*Data Requirements*:\n",
    "* user activity is >80% of all time intervals\n",
    "* month 1, user has >5 rates\n",
    "* month 0, to pre-train model\n",
    "* items are comparable\n",
    "* timestamp\n",
    "* implicit feedback\n",
    "* ranking problem\n",
    "\n",
    "*Conclusion*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# update sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('') + '/..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "from data_utils import getDF\n",
    "from dataset_evaluation_utils import * \n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# import plotly.offline as py\n",
    "# pd.options.plotting.backend = \"plotly\"\n",
    "# py.init_notebook_mode() # graphs charts inline (IPython).\n",
    "\n",
    "a4_dims = (11.7, 8.27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "# R2 - Yahoo!\n",
    "Music User Ratings of Songs with Artist, Album, and Genre Meta Information, \n",
    "v. 1.0 (1.4 Gbyte & 1.1 Gbyte)\n",
    "\n",
    "https://webscope.sandbox.yahoo.com/catalog.php?datatype=r&did=2\n",
    "\n",
    "\n",
    "\\\n",
    "READ.ME:\n",
    "\n",
    "The dataset contains over 717\n",
    "million ratings of 136 thousand songs given by 1.8 million users\n",
    "of Yahoo! Music services. The data was collected between 2002 and 2006. \n",
    "\n",
    "\n",
    "Each song in the data set is accompanied by artist, album,\n",
    "and genre attributes. The users, songs, artists, and albums are\n",
    "represented by randomly assigned numeric id's so that no\n",
    "identifying information is revealed. The mapping from geners id's\n",
    "to geners, as well as the genere hierarchy, is given.\n",
    "\n",
    "\n",
    "The data has been trimmed so that \n",
    "**each user has rated at least 20 songs**, \n",
    "and **each song has been rated by at least 20 users**. \n",
    "\n",
    "The data has been **randomly partitioned into 10 equally sized sets of users** to\n",
    "enable cross-validation techniques. The available ratings for\n",
    "each user have been randomly partitioned into training and test\n",
    "sets to enable all-but-K testing protocols. The test set consist\n",
    "of 10 ratings, and the training set consists of the remaining\n",
    "ratings.\n",
    "\n",
    "**Tab** is used as a delimiter for all data files.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(1-10) \"ydata-ymusic-user-song-ratings-meta-v1_0/train-n.txt\":\\\n",
    "Each training data file contains **training data for 200,000 users**.\n",
    "Each user in each training data file has at least 10 observed\n",
    "ratings. **Each user has at most one observation for each song.** The\n",
    "users are ordered by randomly assigned user id. The observations\n",
    "for each user are listed sequentially, and are ordered by\n",
    "randomly assigned song id. The ratings values are on a scale from\n",
    "1 to 5. The format of each row of each file is \"user id \\<TAB> song\n",
    "id \\<TAB> rating\".\n",
    "\n",
    "Snippet:\\\n",
    "49      2169    5\\\n",
    "49      2180    2\\\n",
    "50      311     5\\\n",
    "50      325     1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/r2_yahoo_dump/\n",
      "output/r2_yahoo_dump/\n",
      "images/r2_yahoo_dump/heatmaps/\n",
      "images/r2_yahoo_dump/diversity_eval/\n",
      "output/r2_yahoo_dump/diversity_eval/\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'R2_Yahoo'\n",
    "dump_foldername ='r2_yahoo_dump/'\n",
    "\n",
    "# rule: what/which_data_set/sample_version/what/\n",
    "images_path, output_path, heatmaps_path, diversity_graphpath, diversity_filepath = get_folderpaths(dump_foldername)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_foldername = 'sample_2014-06_until_2016-11+cold_start_positive_rates/'\n",
    "# images_path, output_path, heatmaps_path, diversity_graphpath, diversity_filepath = get_folderpaths(dump_foldername,\n",
    "                                                                                                #    sample_foldername=sample_foldername)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'R2 - Yahoo! Music User Ratings of Songs with Artist, Album, and Genre Meta Information, v. 1.0 (1.4 Gbyte & 1.1 Gbyte)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_col = 'user_id'\n",
    "# item_col = 'item_id'\n",
    "# rate_col = 'rating'\n",
    "# time_col = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = pd.read_csv(\"../datasets/Digital_Music.csv\", \n",
    "                            names=[item_col, user_col, rate_col, time_col])\n",
    "\n",
    "orig_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  tarfile\n",
    "tar = tarfile.open('../datasets/R2 - Yahoo! Music User Ratings of Songs with Artist, Album, and Genre Meta Information, v. 1.0 (1.4 Gbyte & 1.1 Gbyte)/dataset-1.tgz')\n",
    "members = tar.getmembers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ydata-ymusic-user-song-ratings-meta-v1_0\n",
      "ydata-ymusic-user-song-ratings-meta-v1_0/test_0.txt\n",
      "ydata-ymusic-user-song-ratings-meta-v1_0/test_1.txt\n",
      "ydata-ymusic-user-song-ratings-meta-v1_0/test_2.txt\n",
      "ydata-ymusic-user-song-ratings-meta-v1_0/test_3.txt\n",
      "ydata-ymusic-user-song-ratings-meta-v1_0/test_4.txt\n",
      "ydata-ymusic-user-song-ratings-meta-v1_0/test_5.txt\n",
      "ydata-ymusic-user-song-ratings-meta-v1_0/test_6.txt\n",
      "ydata-ymusic-user-song-ratings-meta-v1_0/test_7.txt\n",
      "ydata-ymusic-user-song-ratings-meta-v1_0/test_8.txt\n",
      "ydata-ymusic-user-song-ratings-meta-v1_0/test_9.txt\n",
      "ydata-ymusic-user-song-ratings-meta-v1_0/train_0.txt\n",
      "ydata-ymusic-user-song-ratings-meta-v1_0/train_1.txt\n",
      "ydata-ymusic-user-song-ratings-meta-v1_0/train_2.txt\n",
      "ydata-ymusic-user-song-ratings-meta-v1_0/train_3.txt\n",
      "ydata-ymusic-user-song-ratings-meta-v1_0/train_4.txt\n",
      "ydata-ymusic-user-song-ratings-meta-v1_0/genre-hierarchy.txt\n",
      "ydata-ymusic-user-song-ratings-meta-v1_0/song-attributes.txt\n",
      "ydata-ymusic-user-song-ratings-meta-v1_0/readme.txt\n"
     ]
    }
   ],
   "source": [
    "for m in members:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ydata-ymusic-user-song-ratings-meta-v1_0/test_0.txt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "non-string returned while reading data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m         content \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m----> 6\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# print(\"%s has %d newlines\" %(m, content.count(\"\\n\")))\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# print(\"%s has %d spaces\" % (m, content.count(\" \")))\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# print(\"%s has %d characters\" % (m, len(content)))\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# sys.exit()\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# tar.close()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\m_f_1st\\lib\\site-packages\\numpy\\lib\\npyio.py:1338\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1336\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1338\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1339\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1340\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1341\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\m_f_1st\\lib\\site-packages\\numpy\\lib\\npyio.py:999\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[0;32m    996\u001b[0m     data \u001b[38;5;241m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_dtype_via_object_chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 999\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_filelike\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimaginary_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimaginary_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiplines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilelike\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilelike\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbyte_converters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbyte_converters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1008\u001b[0m     \u001b[38;5;66;03m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;66;03m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;66;03m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filelike:\n",
      "\u001b[1;31mTypeError\u001b[0m: non-string returned while reading data"
     ]
    }
   ],
   "source": [
    "for m in members[1:2]:\n",
    "    print(m.name)\n",
    "    f = tar.extractfile(m)\n",
    "    if f is not None:\n",
    "        content = f.read()\n",
    "        data = np.loadtxt(content)\n",
    "    # print(\"%s has %d newlines\" %(m, content.count(\"\\n\")))\n",
    "    # print(\"%s has %d spaces\" % (m, content.count(\" \")))\n",
    "    # print(\"%s has %d characters\" % (m, len(content)))\n",
    "    # sys.exit()\n",
    "# tar.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m_f_1st",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
