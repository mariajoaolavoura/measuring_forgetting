{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('') + '/..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import joblib\n",
    "\n",
    "from data import ImplicitData, getBucketsHoldouts\n",
    "from eval_implicit import EvaluateHoldouts \n",
    "from recommenders_implicit import UserKNN\n",
    "\n",
    "from plot_utils import recall_heatmap\n",
    "from data_utils.transfer_learning_scores import *\n",
    "from dataset_evaluation_utils import * \n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# import plotly.offline as py\n",
    "# pd.options.plotting.backend = \"plotly\"\n",
    "# py.init_notebook_mode() # graphs charts inline (IPython).\n",
    "\n",
    "a4_dims = (11.7, 8.27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluate_UKNN(data:pd.DataFrame,\n",
    "                        interval_type:str, \n",
    "                        intervals_path:str, \n",
    "                        use_data_unique_users:bool,\n",
    "                        frequent_users_path:str,\n",
    "                        buckets_path:str,\n",
    "                        holdouts_path:str,\n",
    "                        cold_start_buckets:int,\n",
    "                        to_grid_search:bool,\n",
    "                        k:int,\n",
    "                        similarity:str,\n",
    "                        random_seed:int,\n",
    "                        results_matrix_path:str,\n",
    "                        recall_heatmap_title:str,\n",
    "                        recall_heatmap_path:str,\n",
    "                        incrementalTraining_time_record_path:str,\n",
    "                        evaluateHoldouts_time_record_path:str,\n",
    "                        eval_files_path:str, \n",
    "                        save_eval_files:bool,\n",
    "                        user_col:str = 'user_id',\n",
    "                        item_col:str = 'item_id'):\n",
    "    '''\n",
    "        data: pd.DataFrame, assumes columns ['user_id', 'item_id', 'date', 'timestamp']\n",
    "        interval_type: string | M, Q, S\n",
    "\n",
    "    '''\n",
    "\n",
    "    \n",
    "    frequent_users = joblib.load(frequent_users_path)\n",
    "    frequent_users_idx = None\n",
    "\n",
    "    if interval_type=='Q':\n",
    "        frequent_users_idx = 1\n",
    "        interval_type ='QS'\n",
    "        intervals = joblib.load(intervals_path)\n",
    "\n",
    "        frequent_users[frequent_users_idx] = list(map(int, frequent_users[frequent_users_idx]))\n",
    "\n",
    "        if use_data_unique_users:\n",
    "            frequent_users = (frequent_users[0], data[user_col].unique(), frequent_users[2])\n",
    "\n",
    "    elif interval_type=='S':\n",
    "        frequent_users_idx = 2\n",
    "        interval_type ='QS'\n",
    "        intervals = joblib.load(intervals_path)\n",
    "\n",
    "        frequent_users[frequent_users_idx] = list(map(int, frequent_users[frequent_users_idx]))\n",
    "\n",
    "        if use_data_unique_users:\n",
    "            frequent_users = (frequent_users[0], frequent_users[1], data[user_col].unique())\n",
    "\n",
    "    else:\n",
    "        # assumes monthly interval\n",
    "        interval_type = 'M'\n",
    "        frequent_users_idx = 0 \n",
    "        intervals = None   \n",
    "\n",
    "        frequent_users[frequent_users_idx] = list(map(int, frequent_users[frequent_users_idx]))\n",
    "        \n",
    "        if use_data_unique_users:\n",
    "            frequent_users = (data[user_col].unique(), frequent_users[1], frequent_users[2])\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    print('\\nSTAGE -> getBucketsHoldouts')\n",
    "    buckets, holdouts = getBucketsHoldouts( data = data,\n",
    "                                            user_col = user_col,\n",
    "                                            item_col = item_col,\n",
    "                                            frequent_users = frequent_users[frequent_users_idx],\n",
    "                                            interval_type = interval_type,\n",
    "                                            intervals = intervals, \n",
    "                                            cold_start_buckets = cold_start_buckets)\n",
    "    \n",
    "\n",
    "    joblib.dump(buckets, buckets_path)\n",
    "    joblib.dump(holdouts, holdouts_path)\n",
    "    \n",
    "    print('\\nBucket size, number of users, number of items\\n', [(b.size, len(b.userset), len(b.itemset)) for b in buckets])\n",
    "    print('Holdouts size, number of users, number of items\\n', [(h.size, len(h.userset), len(h.itemset)) for h in holdouts])\n",
    "\n",
    "\n",
    "    print('\\n\\nSTAGE -> to_grid_search')\n",
    "    if to_grid_search:\n",
    "        prop = 0.05 \n",
    "        hp_sample = data.iloc[:round( data.shape[0]*prop )]\n",
    "        stream = ImplicitData(hp_sample[user_col], hp_sample[item_col]) \n",
    "        grid, results = grid_search(model = UserKNN, \n",
    "                                    stream = stream, \n",
    "                                    random_seed = random_seed, \n",
    "                                    interleaved = 100 )\n",
    "        num_factors, num_iter, learn_rate, regularization, _ = grid[ np.argmax( results ) ]\n",
    "\n",
    "    print('num_factors, num_iter, learn_rate, regularization\\n', (num_factors, num_iter, learn_rate, regularization))\n",
    "\n",
    "    print('\\n\\nSTAGE -> ISGD model')\n",
    "    empty_stream = ImplicitData([], []) \n",
    "    model = UserKNN(empty_stream, k=k, similarity=similarity)\n",
    "\n",
    "\n",
    "    print('\\n\\nSTAGE -> EvaluateHoldouts')\n",
    "    eval = EvaluateHoldouts(model = model,\n",
    "                            buckets = buckets,\n",
    "                            holdouts = holdouts)\n",
    "    \n",
    "    if save_eval_files:\n",
    "        eval.Train_Evaluate_Save(eval_files_path, N_recommendations=20, exclude_known_items=True, default_user='none')\n",
    "    else:\n",
    "        eval.Train_Evaluate(N_recommendations=20, exclude_known_items=True, default_user='none')\n",
    "\n",
    "    rm = eval.results_matrix\n",
    "    rm_df = pd.DataFrame(rm)\n",
    "    rm_df.to_csv(results_matrix_path, index=False)\n",
    "    print(rm_df)\n",
    "\n",
    "    recall_heatmap( rm_df,\n",
    "                    round_point = 4,\n",
    "                    title = recall_heatmap_title,\n",
    "                    filepath = recall_heatmap_path) \n",
    "    \n",
    "\n",
    "    print('\\n\\nstage -> metrics')    \n",
    "    arecall = avg_recall(rm_df)\n",
    "    BWT_lr, meanBWT_lr = compute_BWT_lopes_ranzato(rm_df)\n",
    "    BWT_r, meanBWT_r = compute_BWT_rodrigues(rm_df)\n",
    "    FWT_r = compute_FWT_rodrigues(rm_df)\n",
    "\n",
    "    print('avg recall', arecall.round(6))\n",
    "    print('BWT (v. Lopez-Paz e Ranzato GEM 2017), meanBWT', (BWT_lr, meanBWT_lr))\n",
    "    print('BWT (v. DÃ­az-Rodriguez et al. 2018), meanBWT', (BWT_r, meanBWT_r))\n",
    "    print('FWT', FWT_r.round(6))\n",
    "\n",
    "    joblib.dump(eval.IncrementalTraining_time_record, incrementalTraining_time_record_path)\n",
    "    joblib.dump(eval.EvaluateHoldouts_time_record, evaluateHoldouts_time_record_path)\n",
    "\n",
    "\n",
    "    return rm_df, arecall, (BWT_lr, meanBWT_lr), (BWT_r, meanBWT_r), FWT_r\n",
    "\n",
    "\n",
    "def print_heatmap(results_matrix_path, recall_heatmap_title, filepath=False):\n",
    "    rm_df = pd.read_csv(results_matrix_path)\n",
    "    recall_heatmap( rm_df,\n",
    "                    round_point = 4,\n",
    "                    title = recall_heatmap_title,\n",
    "                    filepath = filepath) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'UKNN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folderpath = '../datasets/lastfm1b/'\n",
    "\n",
    "dataset_name = 'LastFM1b'\n",
    "\n",
    "dump_foldername ='lastfm1b_dump/'\n",
    "_, base_outputpath, _, _, _ = get_folderpaths(dump_foldername)\n",
    "\n",
    "\n",
    "period=['2011-07', '2014-01']\n",
    "sample = 'sample_'+str(period[0])+'_until_'+str(period[1])\n",
    "\n",
    "sample_version_dump_foldername=dump_foldername+sample+'/'\n",
    "filename = 'tracks_inter_merged_coldstart_11M'\n",
    "\n",
    "\n",
    "# rule: what/which_data_set/sample_version/what/\n",
    "images_path, output_path, heatmaps_path, diversity_graphpath, diversity_filepath = get_folderpaths(sample_version_dump_foldername)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = pd.read_csv(output_path+filename+'_interactions_df.csv', index_col=0)\n",
    "interactions_df['date'] = interactions_df['date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "interactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.columns = ['user_id','item_id','timestamp','date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_year_month = [(period[0], '%Y-%m'), (period[1], '%Y-%m')]\n",
    "interval_type = 'S'\n",
    "\n",
    "use_data_unique_users = False\n",
    "frequent_users_thr = 0.75\n",
    "cold_start_buckets = 1\n",
    "to_grid_search = False\n",
    "k=10\n",
    "similarity='cosine'\n",
    "random_seed = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path+filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_evaluate_UKNN(data = interactions_df,\n",
    "             interval_type = 'S',\n",
    "             intervals_path = output_path+filename+'_semesters.joblib',\n",
    "             use_data_unique_users = False,\n",
    "             frequent_users_path = output_path+filename+'_frequent_users_'+str(frequent_users_thr)+'.joblib',\n",
    "             buckets_path = output_path+filename+'_semesterly_buckets.joblib',\n",
    "             holdouts_path = output_path+filename+'_semesterly_holdouts.joblib',\n",
    "             cold_start_buckets = 1,\n",
    "             to_grid_search = False,\n",
    "             k=k,\n",
    "             similarity=similarity,\n",
    "             random_seed = random_seed,\n",
    "             results_matrix_path = output_path+filename+'_semesterly_bucket_'+MODEL_NAME+'_results.csv',\n",
    "             recall_heatmap_title = 'Recall@20 for '+MODEL_NAME+' checkpoints across Holdouts (2013/2014) - '+dataset_name,\n",
    "             recall_heatmap_path = heatmaps_path+filename+'_semesterly_bucket_'+MODEL_NAME+'_heatmap.png',\n",
    "             incrementalTraining_time_record_path = output_path+filename+'_semesterly_bucket_'+MODEL_NAME+'_training_time.joblib',\n",
    "             evaluateHoldouts_time_record_path = output_path+filename+'_semesterly_bucket_'+MODEL_NAME+'_eval_time.joblib',\n",
    "             eval_files_path = diversity_filepath+MODEL_NAME+'/'+filename+'_',\n",
    "             save_eval_files = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m_f_1st",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
