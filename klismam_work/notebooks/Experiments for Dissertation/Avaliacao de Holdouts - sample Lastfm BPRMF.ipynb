{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação em holdouts - LASTFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('') + '/..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import ImplicitData, getBucketsHoldouts\n",
    "from plot_utils import lineplot_recallxholdout, recall_heatmap\n",
    "from dataset_evaluation_utils import *\n",
    "from flurs.recommender import BPRMFRecommender, SketchRecommender\n",
    "from eval_implicit import EvaluateHoldoutsFlurs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## BWT FWT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACC, BWT, e FWT - Lopez-Paz e Ranzato GEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_recall(results_matrix): # Lopez-Paz e Ranzato GEM 2017\n",
    "    return np.mean( np.diag(results_matrix) )\n",
    "\n",
    "def compute_BWT(results_matrix): # Lopez-Paz e Ranzato GEM 2017\n",
    "    BWT = []\n",
    "    n_checkpoints = results_matrix.shape[0]\n",
    "    for T in range(1, n_checkpoints): # 1 means holdout 2, 2 means 3, so on\n",
    "        Rti = results_matrix.iloc[T, 0:T] # get models performances' on previous holdouts\n",
    "        Rii = np.diag(results_matrix)[0:T] # get models performances' on their closest holdouts (diagonal)\n",
    "        E = sum( Rti - Rii ) # future models performances' - performances' of models closest to holdouts (diagonal)\n",
    "        BWT.append( E/T ) # store average BWT for model\n",
    "    return BWT, np.mean( BWT ) # return BWT and average BWT for all models\n",
    "\n",
    "def compute_FWT(results_matrix): # Díaz-Rodriguez et al. 2018\n",
    "    upper_tri = results_matrix.to_numpy()[np.triu_indices(results_matrix.shape[0], k=1)]\n",
    "    return np.mean(upper_tri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPRMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa dataset 'palco playlists'\n",
    "data = pd.read_csv('output/lastfm_dump/sampled_lastfm.csv')\n",
    "user_col = 'user_id'\n",
    "item_col = 'item_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = joblib.load( 'output/lastfm_dump/sample_buckets.joblib')\n",
    "holdouts = joblib.load( 'output/lastfm_dump/sample_holdouts.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 %\n",
      "1.0 %\n",
      "2.0 %\n",
      "3.0 %\n",
      "4.0 %\n",
      "5.0 %\n",
      "6.0 %\n",
      "7.0 %\n",
      "8.0 %\n",
      "9.0 %\n",
      "10.0 %\n",
      "11.0 %\n",
      "12.0 %\n",
      "13.0 %\n",
      "14.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kpereira/.virtualenvs/streamrec_venv/lib/python3.8/site-packages/flurs/model/bprmf.py:40: RuntimeWarning: overflow encountered in double_scalars\n",
      "  sigmoid = np.e ** (-x_uij) / (1 + np.e ** (-x_uij))\n",
      "/home/kpereira/.virtualenvs/streamrec_venv/lib/python3.8/site-packages/flurs/model/bprmf.py:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sigmoid = np.e ** (-x_uij) / (1 + np.e ** (-x_uij))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0 %\n",
      "16.0 %\n",
      "17.0 %\n",
      "18.0 %\n",
      "19.0 %\n",
      "20.0 %\n",
      "21.0 %\n",
      "22.0 %\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import itertools\n",
    "from flurs.data.entity import User, Item, Event\n",
    "def grid_search(model, data, user_col, item_col, exclude_known_items, N_recommendations=-1):    \n",
    "#     try:\n",
    "        usermap = pd.Series(pd.unique( data[user_col] )).reset_index().set_index(0).to_dict()['index']\n",
    "        itemmap = pd.Series(pd.unique( data[item_col] )).reset_index().set_index(0).to_dict()['index']\n",
    "        num_factors = [50, 100, 150, 200]\n",
    "        regularization = [0.01, 0.05, 0.1, 0.25, 0.5]\n",
    "        learn_rate = [0.01, 0.05, 0.1, 0.25, 0.5]\n",
    "        grid = [num_factors, regularization, learn_rate]\n",
    "        grid = list(itertools.product(*grid))\n",
    "        results = []\n",
    "        p0=-1\n",
    "        for i, hp in enumerate(grid):\n",
    "            progress = ((i*100)//len(grid))\n",
    "            if progress%5==0 and progress!=p0:\n",
    "                p0=progress\n",
    "                print(progress, '%')\n",
    "            nf, reg, lr = hp\n",
    "            m = model(k=nf, l2_reg=reg, learn_rate=lr)     \n",
    "            m.initialize()\n",
    "            max_item_ID = 0\n",
    "            empty_stream = ImplicitData([], []) # used to track items seen by users\n",
    "            iteration_results = []\n",
    "            for u, i in data[[user_col, item_col]].values:\n",
    "                u_flurs, i_flurs = usermap[u], itemmap[i]\n",
    "                max_item_ID = max(max_item_ID, i_flurs)\n",
    "                user = User(u_flurs)\n",
    "                item = Item(i_flurs)\n",
    "                event = Event(user, item)\n",
    "                m.register(user)\n",
    "                m.register(item)\n",
    "                # Prequential:\n",
    "                # recommend\n",
    "                reclist, scores = m.recommend(user, np.arange(max_item_ID+1) )                \n",
    "#                 print(u_flurs, i_flurs, reclist[:10], scores[:10]) # \n",
    "                if exclude_known_items:\n",
    "                    user_items = empty_stream.GetUserItems(u_flurs)\n",
    "                    reclist = np.delete(reclist, user_items)\n",
    "                # get n recommendations\n",
    "                n = N_recommendations\n",
    "                if n == -1:\n",
    "                    n = len(reclist)\n",
    "                reclist = reclist[:n]\n",
    "                # evaluate\n",
    "                result = 0\n",
    "                if len(reclist) == 0:\n",
    "                    iteration_results.append( 0 )\n",
    "                else:\n",
    "                    iteration_results.append( int(i_flurs in reclist) )\n",
    "                # update\n",
    "                empty_stream.AddFeedback(u_flurs, i_flurs) #\n",
    "                m.update(event)\n",
    "\n",
    "            results.append( np.mean( iteration_results ) )\n",
    "#             print ( np.mean( iteration_results ), len( iteration_results ))\n",
    "            \n",
    "        return grid, results    \n",
    "    \n",
    "#     except:\n",
    "#         print(u, i, u_flurs, i_flurs, max_item_ID, user, item, user_items)\n",
    "\n",
    "prop = 0.05\n",
    "hp_sample = data.iloc[:round( data.shape[0]*prop )]\n",
    "# 4h 17min 22s\n",
    "grid, results = grid_search(model=BPRMFRecommender, data=hp_sample, user_col=user_col, item_col=item_col, exclude_known_items=True, N_recommendations=20)\n",
    "len(grid), len(results), max(results) # (27, 27, 0.03681617837697693)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous (50, 0.5, 0.5)\n",
    "print( grid[ np.argmax( results ) ] )\n",
    "k, l2_reg, learn_rate = grid[ np.argmax( results ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se o stream for passado, ao excluir itens conhecidos o recall é sempre 0. Ao permitir a recomendação de itens já vistos, o recall não é 0.\n",
    "# model = BPRMFRecommender(k=num_factors, l2_reg=regularization, learn_rate=learn_rate)\n",
    "model = BPRMFRecommender(k, l2_reg, learn_rate )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criamos instancia de EvaluateHoldouts para treinar o modelo e avaliar checkpoints\n",
    "eval = EvaluateHoldoutsFlurs(model, buckets, holdouts, data, user_col, item_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 1h 12min 53s\n",
    "eval.Train_Evaluate(N_recommendations = 20, exclude_known_items = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.0 freq T\n",
    "rm = eval.results_matrix\n",
    "df = pd.DataFrame(rm)\n",
    "df.to_csv('output/lastfm_dump/sample_lastfm month_bucket BPRMF results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_heatmap(df,\n",
    "               round_point=4,\n",
    "    title='Recall@20 for BPRMF checkpoints across Holdouts - Lastfm',\n",
    "    filepath='images/heatmaps/lastfm_dump/sample_lastfm month_bucket BPRMF heatmap.png') #='images/heatmaps/palco_2010 month_bucket ISGD heatmap.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arecall = avg_recall(df)\n",
    "arecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BWT, meanBWT = compute_BWT(df)\n",
    "BWT, meanBWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWT = compute_FWT(df)\n",
    "FWT\n",
    "# que itens que usuario utilizou no passado e deixou de consumir o sistema ainda pode recomendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(eval.IncrementalTraining_time_record, 'output/lastfm_dump/sample_lastfm month_bucket BPRMF training time.joblib')\n",
    "joblib.dump(eval.EvaluateHoldouts_time_record, 'output/lastfm_dump/sample_lastfm month_bucket BPRMF eval time.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('dissertacao')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "93164e1ba08303257f1d4f69270dc17556e83319233af9462e0c249160adc063"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
